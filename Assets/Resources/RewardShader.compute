// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel HumanReward

RWStructuredBuffer<float> mass;
RWStructuredBuffer<float2x3> velocities;
RWStructuredBuffer<float2x3> previous_velocities;
RWStructuredBuffer<float4x3> results;
groupshared float2x3 avg_velocity[32];
groupshared float2x3 avg_acceleration[32];

[numthreads(2,32,1)]
void HumanReward (uint3 id : SV_DispatchThreadID)
{
    uint flatIndex = id.z * 32 + id.y;
    
    avg_velocity[id.y][id.x].xyz = mul(velocities[flatIndex][id.x].xyz, mass[id.y]);
    avg_acceleration[id.y][id.x].xyz = mul(velocities[flatIndex][id.x].xyz - previous_velocities[flatIndex][id.x].xyz, mass[id.y]);
    GroupMemoryBarrierWithGroupSync();

    // do reduction in shared mem
    if (id.y < 16) {
        avg_velocity[id.y][id.x].xyz += avg_velocity[id.y + 16][id.x].xyz;
        avg_acceleration[id.y][id.x].xyz += avg_acceleration[id.y + 16][id.x].xyz;
    }
    if (id.y < 8) {
        avg_velocity[id.y][id.x].xyz += avg_velocity[id.y + 8][id.x].xyz;
        avg_acceleration[id.y][id.x].xyz += avg_acceleration[id.y + 8][id.x].xyz;
    }
    if (id.y < 4) {
        avg_velocity[id.y][id.x].xyz += avg_velocity[id.y + 4][id.x].xyz;
        avg_acceleration[id.y][id.x].xyz += avg_acceleration[id.y + 4][id.x].xyz;
    }
    if (id.y < 2) {
        avg_velocity[id.y][id.x].xyz += avg_velocity[id.y + 2][id.x].xyz;
        avg_acceleration[id.y][id.x].xyz += avg_acceleration[id.y + 2][id.x].xyz;
    }

    // write result for this block to global mem
    if (id.y == 0) {
        avg_velocity[0][id.x] += avg_velocity[1][id.x];
        avg_acceleration[0][id.x] += avg_acceleration[1][id.x];
        float2x3 res = {
            avg_velocity[0][id.x],
            avg_acceleration[0][id.x]
        };
        results[id.z][id.x] = res[id.x];
    }
    previous_velocities[flatIndex][id.x].xyz = velocities[flatIndex][id.x].xyz;
}
