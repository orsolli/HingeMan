{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Unity ML Agents\n",
    "## Environment Basics\n",
    "This notebook contains a walkthrough of the basic functions of the Python API for Unity ML Agents. For instructions on building a Unity environment, see [here](https://github.com/Unity-Technologies/ml-agents/wiki/Getting-Started-with-Balance-Ball)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Set environment parameters\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env_name = \"Crawler\" # Name of the Unity environment binary to launch\n",
    "train_mode = True # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "WARNING:unityagents: No External Brains found in the Unity Environment. You will not be able to pass actions to your agent(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\tsteps -> 0.0\n",
      "Unity brain name: Brain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 225\n",
      "        Action space type: continuous\n",
      "        Action space size (per agent): 24\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: , , , , , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent state looks like: \n",
      "[  1.83641500e-05   2.46989275e-05   9.00711100e-06  -1.96977379e-03\n",
      "  -6.12099200e-01  -4.62391065e-04   1.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -3.68781700e-05  -1.63792849e-01  -1.49482346e+00\n",
      "  -7.40916600e-01  -2.54466322e-05  -2.43460636e-05   6.71597064e-01\n",
      "  -3.34053620e-04  -1.48338330e+00   8.12849551e-02  -8.75210762e-01\n",
      "  -5.58397500e-04  -7.26644976e-06  -1.05708158e+00  -1.63798332e-01\n",
      "  -1.05704500e+00  -6.84526400e-01   2.56991237e-01   2.83523083e-01\n",
      "   6.20478700e-01   5.66791631e-02  -1.48340583e+00   5.74637242e-02\n",
      "  -6.18840635e-01  -1.07659411e-03   6.19021300e-01  -1.49546766e+00\n",
      "  -1.63816214e-01   0.00000000e+00  -5.23886700e-01   4.74914342e-01\n",
      "   5.23883400e-01   4.74916160e-01   7.21765600e-02  -1.48341215e+00\n",
      "   1.85255249e-05  -2.35804800e-05  -3.59529900e-05   8.73600600e-01\n",
      "  -1.05707741e+00  -1.63793325e-01   1.05703354e+00  -2.83518583e-01\n",
      "   6.20480955e-01   6.84525967e-01   2.56991923e-01   5.67014500e-02\n",
      "  -1.48337662e+00  -5.61335900e-02   6.19221568e-01  -9.79152900e-04\n",
      "   6.18872762e-01  -4.09668600e-05  -1.63791656e-01   1.49481964e+00\n",
      "   2.82950532e-05   6.71599500e-01   7.40914345e-01  -2.63313232e-05\n",
      "   1.74993227e-04  -1.48327482e+00  -8.07788149e-02   8.75471400e-01\n",
      "  -5.35916400e-04  -2.44075316e-04   1.05729663e+00  -1.63799286e-01\n",
      "   1.05734253e+00   2.83540428e-01   6.20494800e-01   6.84486700e-01\n",
      "  -2.57039070e-01  -5.02556264e-02  -1.48314643e+00  -5.03641100e-02\n",
      "   6.17901100e-01  -9.53737239e-04  -6.17883742e-01   1.49524400e+00\n",
      "  -1.63802385e-01   0.00000000e+00   5.23886740e-01   4.74912435e-01\n",
      "   5.23887038e-01  -4.74914044e-01  -7.14340700e-02  -1.48316312e+00\n",
      "  -2.82405700e-04  -4.64457900e-05  -9.75359755e-04  -8.73837531e-01\n",
      "   1.05730391e+00  -1.63802385e-01  -1.05733871e+00   6.84485900e-01\n",
      "   2.57037282e-01   2.83543080e-01  -6.20495141e-01  -5.08299842e-02\n",
      "  -1.48315573e+00   5.00833300e-02  -6.17973600e-01  -1.14188700e-03\n",
      "  -6.17956300e-01   7.70823500e-06  -2.26607323e-01  -3.49067300e+00\n",
      "  -6.94570100e-01   8.73280351e-06   9.26198500e-06   7.19425100e-01\n",
      "   7.81225244e-05  -2.05800676e+00   1.49765536e-01   2.98390239e-01\n",
      "   2.50135956e-04   3.45357257e-05  -2.46833777e+00  -2.26608515e-01\n",
      "  -2.46834564e+00  -6.41692936e-01   2.75321000e-01   2.65802920e-01\n",
      "   6.64663400e-01   1.05584666e-01  -2.05802155e+00   1.05427340e-01\n",
      "   2.11013213e-01   3.64158273e-04  -2.11133987e-01  -3.49132442e+00\n",
      "  -2.26625200e-01   0.00000000e+00  -4.91153926e-01   5.08691500e-01\n",
      "   4.91156042e-01   5.08691100e-01   1.40466541e-01  -2.05841446e+00\n",
      "  -3.70863677e-06   2.31050362e-05   1.15642533e-05  -2.96589762e-01\n",
      "  -2.46833253e+00  -2.26608753e-01   2.46833420e+00  -2.65808200e-01\n",
      "   6.64661700e-01   6.41693700e-01   2.75318116e-01   1.04781449e-01\n",
      "  -2.05806700e+00  -1.04862936e-01  -2.11284700e-01   2.10911472e-04\n",
      "  -2.11026818e-01   8.71925100e-06  -2.26606846e-01   3.49066925e+00\n",
      "  -1.26564073e-05   7.19424000e-01   6.94571257e-01   7.65771800e-06\n",
      "  -1.18348400e-05  -2.05804600e+00  -1.49274200e-01  -2.98510164e-01\n",
      "   5.68268300e-05   2.12951374e-04   2.46862400e+00  -2.26621628e-01\n",
      "   2.46861649e+00   2.65805800e-01   6.64636100e-01   6.41732100e-01\n",
      "  -2.75292754e-01  -1.03508048e-01  -2.05822349e+00  -1.03649430e-01\n",
      "  -2.09079385e-01  -3.27011600e-04   2.09041670e-01   3.49112368e+00\n",
      "  -2.26620913e-01   0.00000000e+00   4.91156900e-01   5.08689500e-01\n",
      "   4.91160035e-01  -5.08686300e-01  -1.46926031e-01  -2.05820513e+00\n",
      "  -4.40376500e-06  -2.14289116e-07  -1.22029178e-05   2.95616000e-01\n",
      "   2.46863055e+00  -2.26620674e-01  -2.46862030e+00   6.41731900e-01\n",
      "   2.75296000e-01   2.65807629e-01  -6.64634200e-01  -1.03494488e-01\n",
      "  -2.05820155e+00   1.03622168e-01   2.08970711e-01   2.99178151e-04\n",
      "   2.09053710e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Agent state looks like: \\n{}\".format(env_info.states[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "for observation in env_info.observations:\n",
    "    print(\"Agent observations look like:\")\n",
    "    if observation.shape[3] == 3:\n",
    "        plt.imshow(observation[0,:,:,:])\n",
    "    else:\n",
    "        plt.imshow(observation[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Take random actions in the environment\n",
    "Once we restart an environment, we can step the environment forward and provide actions to all of the agents within the environment. Here we simply choose random actions based on the `action_space_type` of the default brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "UnityActionException",
     "evalue": "There are no external brains in the environment, step cannot take an action input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityActionException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-909908fbed1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'continuous'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             env_info = env.step(np.random.randn(len(env_info.agents), \n\u001b[0;32m----> 8\u001b[0;31m                                                 brain.action_space_size))[default_brain]\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             env_info = env.step(np.random.randint(0, brain.action_space_size, \n",
      "\u001b[0;32m/home/orjans/dev/EGDE/AI/ml-agents/python/Crawler/unityagents/environment.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, memory, value)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                     raise UnityActionException(\n\u001b[0;32m--> 375\u001b[0;31m                         \u001b[0;34m\"There are no external brains in the environment, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m                         \"step cannot take an action input\")\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityActionException\u001b[0m: There are no external brains in the environment, step cannot take an action input"
     ]
    }
   ],
   "source": [
    "for episode in range(10):\n",
    "    env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "    done = False\n",
    "    episode_rewards = 0\n",
    "    while not done:\n",
    "        if brain.action_space_type == 'continuous':\n",
    "            env_info = env.step(np.random.randn(len(env_info.agents), \n",
    "                                                brain.action_space_size))[default_brain]\n",
    "        else:\n",
    "            env_info = env.step(np.random.randint(0, brain.action_space_size, \n",
    "                                                  size=(len(env_info.agents))))[default_brain]\n",
    "        episode_rewards += env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "    print(\"Total reward this episode: {}\".format(episode_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6. Close the environment when finished\n",
    "When we are finished using an environment, we can close it with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
